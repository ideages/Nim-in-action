

6 Concurrency
===========


This chapter covers:



* The importance of concurrency
* Concurrency vs parallelism
* Threads in Nim
* Advanced parsing of data using regular expressions and other means
* Parallelising the parsing of large data sets



Every computer program performs one or more computations. These computations are usually performed *sequentially*. That is, the current computation has to complete before the next one starts. For example, consider a simple calculation `(2 + 2) * 4`, in which the addition must be computed first to give `4`, followed by the multiplication to give `16`. In that example the calculation is performed sequentially. *Concurrency* allows more than one computation to make progress without waiting for all the other computations to complete. This form of computing is useful in many situations. One example is an input/output application like the chat application that you developed in *Chapter 3*. When executed sequentially, such applications would waste time waiting on input or output operations to complete. Concurrency allows this time to be used for another task, drastically reducing the execution time of the application.


Nim offers many built-in facilities for concurrency. These include the asynchronous I/O features in the form of Futures and `await`, as well as `spawn` for creating new threads, and more. You have already seen some of those used in *Chapter 3*.


Concurrency in Nim is still evolving, which means that the features described in this chapter may change or be replaced by new more robust features. But the core concepts of concurrency in Nim should remain the same, and what you will learn in this chapter will be applicable to other programming languages as well.


In addition to showing you Nim’s concurrency features, this chapter will lead you through the implementation of a simple parser, which will show you the different methods for creating parsers. This chapter will then end by optimising the parser so that it is concurrent and can be run in *parallel* on multiple CPU cores.




6.1  Concurrency vs. Parallelism
================================



Nowadays almost all operating systems support *multitasking*, which is the ability to perform multiple tasks over a certain period of time. A task is usually known as a *process*, which is an instance of a computer program being executed. Each CPU executes only a single process at a time. Multitasking allows the operating system to change the process which is currently being executed on the CPU, without having to wait for the process to finish its execution. *Figure 6.1* shows how two processes are executed concurrently on a multitasking operating system.




Figure 6.1. Concurrent execution of two processes


![ch06 process execution](../Images/ch06_process_execution.png)

Because CPUs are extremely fast, process A can be executed for 1 nanosecond, followed by process B for 2 nanoseconds, followed by process A for another nanosecond. This gives the impression of multiple processes being executed "at the same time". But that cannot happen, because a CPU can only execute a single instruction at a time. This apparent execution of multiple processes simultaneously is called concurrency.


In recent years, multi-core CPUs have become popular. These kinds of CPUs consist of two or more independent units which can run multiple instructions simultaneously. This allows a multitasking operating system to run two or more processes at the same time in *parallel*. *Figure 6.2* shows how two processes are executed in parallel on a dual-core CPU.




Figure 6.2. Parallel execution of two processes


![ch06 process execution parallel](../Images/ch06_process_execution_parallel.png)

Contrary to a single-core CPU, a dual-core CPU can actually execute two processes at the same time. This type of execution is called parallelism, and it can only be achieved on multiple physical CPUs. Remember that despite the apparent similarities between concurrency and parallelism, the two are not the same.


In addition to processes, the operating system also manages the execution of *threads*. A thread is a component of a process, and more than one can exist within the same process. It can be executed concurrently or in parallel just like a process, although unlike processes, threads share resources such as memory between each other.


In order to make use of the full power of a multi-core CPU, CPU-intensive computations must be parallelised. This can be done by using multiple processes, although threads are more appropriate for computations which require a large amount of data to be shared.


The asynchronous await that you have seen used in *Chapter 3* is strictly concurrent. Because the asynchronous code always runs on a single thread it is not parallel. This means that it cannot currently use the full power of multi-core CPUs.





 > Note Parallel async await 
 It is very likely that a future version of Nim will include asynchronous await which is parallel. 



Unlike asynchronous await, `spawn` is parallel and has been designed specifically for CPU-intensive computations which can benefit from being executed on multi-core CPUs.





> Note Parallelism in other programming languages |
| Some programming languages such as Python and Ruby do not support Thread-level parallelism due to a Global Interpreter Lock that is present in their interpreter. This prevents applications which use threads from using the full power of multi-core CPUs. There are ways around this limitation, but they require the use of processes which are not as flexible as threads. |







6.2  Using threads in Nim
=========================



Now that you have learned about the difference between concurrency and parallelism, you are ready to learn how to use threads in Nim.


In Nim, there are two modules for working with threads. The `threads` module [[19]](#ftn.d5e6428) exposes the ability to create threads manually, threads created using this method immediately execute a specified procedure and run for the duration of that procedure’s runtime. There is also the `threadpool` module [[20]](#ftn.d5e6432) which implements a *thread pool*, it exposes `spawn` which adds a specified procedure to the thread pool’s *task queue*. The act of *spawning* a procedure does not mean it will be running in a separate thread immediately though. The creation of threads is managed entirely by the thread pool.


The sections which follow will teach you all about the two different threading modules, so don’t feel overwhelmed about the new terms introduced in the last paragraph.




6.2.1  The `threads` module and GC safety
-----------------------------------------



In this section I’m going to look at the `threads` module. But before I start I must explain how threads work in Nim, in particular you will learn about what *Garbage Collector safety* is in Nim. There is a very important distinction between the way that threads work in Nim and in most other programming languages. Each of Nim’s threads has its own isolated *heap* of memory. Sharing of memory between threads is restricted, which helps to prevent race conditions and improves efficiency.


Efficiency is improved as a result of each thread having its own garbage collector. Other implementations of threads which share memory need to pause all threads while the garbage collector does its business. This can add problematic pauses to the application.


Let me show you how this threading model works in practice. *Listing 6.1* shows a code sample which does not compile.




Listing 6.1. Mutating a global variable using a `Thread`.




```
var data = "Hello World"               ❶

proc showData() {.thread.} =           ❷
  echo(data)                           ❸

var thread: Thread[void]               ❹
createThread[void](thread, showData)   ❺
joinThread(thread)                     ❻
```




|  |  |
| --- | --- |
| [❶](#CO1-1) | Define a new mutable global variable `data` and assign the text `"Hello World"` to it. |
| [❷](#CO1-2) | Define a new procedure which will be executed in a new thread. The `{.thread.}` pragma must be used to signify this. |
| [❸](#CO1-3) | Attempt to display the value of the `data` variable. |
| [❹](#CO1-4) | Define a variable to store the new thread, the generic parameter signifies the type of parameter that the thread procedure takes. In this case the `void` means that the procedure takes no parameters. |
| [❺](#CO1-5) | The `createThread` procedure executes the specified procedure in a new thread. |
| [❻](#CO1-6) | Wait for `thread` to finish. |





 





> Note The `threads` module |
| The `threads` module is a part of the implicitly imported `system` module, so you do not need to import it explicitly. |



This example illustrates what is disallowed by the *GC safety* mechanism in Nim, and you will see later on how to fix the example so that it compiles. Save the code in *Listing 6.1* as `listing01.nim`, then execute `nim c --threads:on listing01.nim` to compile it. The `--threads:on` flag is necessary to enable thread support. You should see an error similar to the one in *Listing 6.2*.




Listing 6.2. Compilation output for *Listing 6.1*




```
listing01.nim(3, 6) Error: 'showData' is not GC-safe as it accesses 'data' which is a global using GC'ed memory
```



The error describes the problem fairly well. The global variable `data` has been created in the main thread, so it belongs to the main thread’s memory. The `showData` thread cannot access another thread’s memory, and if it attempts to then it is not considered *GC-safe* by the compiler. The compiler refuses to execute threads which are not GC-safe.


A procedure is considered GC-safe by the compiler as long as it does not access any global variables that contain garbage collected memory. An assignment or any sort of mutation also counts as an access and is disallowed. Garbage collected memory includes (but is not limited to) the following types of variables:



* `string`
* `seq[T]`
* `ref T`



There are other ways of sharing memory between threads which are GC-safe. You may for example pass the contents of `data` as one of the parameters to `showData`. *Listing 6.3* shows how to pass data as a parameter to a thread, the differences between *Listing 6.3* and *Listing 6.1* are shown in bold.




Listing 6.3. Passing data to a thread safely




```
var data = "Hello World"

proc showData(**param: string**) {.thread.} =   ❶
  echo(**param**)   ❷

var thread: Thread[**string**]   ❸
createThread[**string**](thread, showData**, data**)   ❹
joinThread(thread)
```




|  |  |
| --- | --- |
| [❶](#CO2-1) | This time a parameter of type `string` is specified in the procedure definition. |
| [❷](#CO2-2) | The procedure argument is passed to `echo` instead of the global variable `data`. |
| [❸](#CO2-3) | The `void` has been replaced by `string` to signify the type of parameter which the `showData` procedure takes. |
| [❹](#CO2-4) | The `data` global variable is passed to the `createThread` procedure, which will pass it onto `showData`. |





Save the code in *Listing 6.3* as `listing2.nim`, then compile it using `nim c --threads:on listing2.nim`. The compilation should be successful and running the program should display `"Hello World"`.


The `createThread` procedure can only pass one variable to the thread that it is creating. In order to pass multiple separate pieces of data to the thread, you must define a new type to hold the data. The listing below shows how this can be done.




```
type
  ThreadData = object
    param: string
    param2: int


var data = "Hello World"

proc showData(**data: ThreadData**) {.thread.} =
  echo(**data.param, data.param2**)

var thread: Thread[**ThreadData**]
createThread[**ThreadData**](thread, showData, **ThreadData(param: data, param2: 10)**)
joinThread(thread)
```




### Execution of threads



So far the threads created in the listings above haven’t done very much. Let’s examine the execution of these threads, by seeing what happens when two threads are created at the same time and are instructed to display a few lines of text-- in the following examples, two series of integers are displayed.




Listing 6.4. Executing multiple threads




```
var data = "Hello World"

proc countData(param: string) {.thread.} =
  for i in 0 .. <param.len:   ❶
    stdout.write($i)          ❷
  echo()                      ❸

var threads: array[2, Thread[string]]               ❹
createThread[string](threads[0], countData, data)   ❺
createThread[string](threads[1], countData, data)   ❺
joinThreads(threads)          ❻
```




|  |  |
| --- | --- |
| [❶](#CO3-1) | Iterate from 0 to the length of the argument `param` minus 1. |
| [❷](#CO3-2) | Display the current iteration counter without displaying the new line character. |
| [❸](#CO3-3) | Go to the next line. |
| [❹](#CO3-4) | This time there are two threads, they are stored in an array. |
| [❺](#CO3-5) | Create a thread and assign it to one of the elements in the `threads` array. |
| [❻](#CO3-7) | Wait for all the threads to finish. |





Save the code in *Listing 6.4* as `listing3.nim`, then compile and run it. *Listing 6.5* shows what the output will look like in most cases and *Listing 6.6* shows what it may sometimes look like instead.




Listing 6.5. First possible output when code in *Listing 6.4* is executed




```
001122334455667788991010
```





Listing 6.6. Second possible output when code in *Listing 6.4* is executed




```
012345678910
012345678910
```



The execution of the threads depends entirely on the operating system and computer used. On my machine the output in *Listing 6.5* likely happens as a result of the two threads running in parallel on two CPU cores. Whereas the output in *Listing 6.6* is a result of the first thread finishing before the second thread even started. Your system may show completely different results. *Figure 6.3* shows what the execution for both the first and second set of results looks like.




Figure 6.3. The two possible executions of *Listing 6.4*


![ch06 thread printing](../Images/ch06_thread_printing.png)

The threads created using the `threads` module are considerably resource intensive. They consume a lot of memory and so you should not create large amounts of them as that would be inefficient. They are useful if you would like to have full control over the threads that your application is using but for most use cases the `threadpool` module is superior. Let’s take at how the `threadpool` module works now.






6.2.2  Using thread pools
-------------------------



The main purpose to using multiple threads is the parallelization of code. CPU-intensive computations should make use of as much CPU power as possible, this includes using the power of all the cores in a system with a multi-core CPU.


A single thread can utilise the power of a single CPU core. So in order to utilise the power of all cores, you could simply create one thread per core. The biggest problem then is making sure that those threads are all busy. You might have 100 tasks which don’t all take the same amount of time to complete, distributing them across the threads is not trivial.


Alternatively a thread per task could be created. But this has problems of its own, one of them is that thread creation is very expensive. A large amount of threads would consume a lot of memory.


**What is a thread pool?**


The `threadpool` module implements an abstraction which manages the distribution of tasks over a number of threads. The threads themselves are also managed by the thread pool.


The `spawn` procedure allows tasks, in the form of procedures, to be added to the thread pool. The thread pool executes the given procedures in one of the threads that it manages. It ensures that the procedures keep all of the threads busy so that the CPU’s power is utilised in the best way possible. *Figure 6.4* shows how the thread pool manages tasks under the hood.




Figure 6.4. A Nim thread pool


![ch06 thread pool](../Images/ch06_thread_pool.png)

**Using `spawn`**


The `spawn` procedure accepts an expression. In most cases the expression is a procedure call. `Spawn` returns a value of the type `FlowVar[T]`, which holds the return value of the procedure that was called. This is an advantage in comparison to the `threads` module, in which threads cannot return any values.


*Listing 6.7* shows the `spawn` equivalent of the code in *Listing 6.4*.




Listing 6.7. Executing multiple threads using `spawn`




```
import threadpool   ❶
var data = "Hello World"

proc countData(param: string) =   ❷
  for i in 0 .. <param.len:
    stdout.write($i)
  echo()

spawn countData(data)   ❸
spawn countData(data)

sync()   ❹
```




|  |  |
| --- | --- |
| [❶](#CO4-1) | The `threadpool` module needs to be explicitly imported in order to use `spawn`. |
| [❷](#CO4-2) | The procedure which is passed to `spawn` does not need the `{.thread.}` pragma. |
| [❸](#CO4-3) | The syntax for *spawning* the procedure is much simpler. |
| [❹](#CO4-4) | The `sync` procedure is used to wait for all spawned procedures to finish. |





Save the code in *Listing 6.7* as `listing4.nim`, then compile and run it. Keep in mind that the `--threads:on` flag still needs to be specified. The output should be mostly the same as the output shown in *Listings 6.5 and 6.6*.


Procedures executed using `spawn` also have to be GC safe.


**Retrieving return values from the `FlowVar` type**


Let’s look at an example which shows how to retrieve the return values from a spawned procedure. This involves dealing with the `FlowVar[T]` type. This type can be thought of as a container similar to the `Future[T]` type, which you’ve used in *Chapter 3*. At first, the container has nothing inside it. When the spawned procedure is executed in a separate thread, at some point in the future it returns a value. When that happens the returned value is put into the `FlowVar` container.


*Listing 6.8* shows the `readLine` procedure from *Chapter 3*, with a while loop which was used to read text from the terminal without blocking.




Listing 6.8. Reading input from the terminal with spawn




```
import threadpool, os   ❶

let lineFlowVar = spawn stdin.readLine()   ❷
while not lineFlowVar.isReady:   ❸
  echo("No input received.")     ❹
  echo("Will check again in 5 seconds.")   ❹
  sleep(5000)           ❺

echo("Input received: ", ^lineFlowVar)     ❻
```




|  |  |
| --- | --- |
| [❶](#CO5-1) | The `threadpool` module is necessary for spawn. The `os` module defines the `sleep` procedure. |
| [❷](#CO5-2) | Add the `readLine` procedure to the thread pool, `spawn` will return a `FlowVar[string]` type which will be assigned to the `lineFlowVar` variable. |
| [❸](#CO5-3) | Loop until `lineFlowVar` contains the string value returned by `readLine`. |
| [❹](#CO5-4) | Display some status messages about what the program is doing. |
| [❺](#CO5-6) | Suspend the main thread for 5 seconds, `sleep`'s parameter is in milliseconds. |
| [❻](#CO5-7) | When the loop finishes the `lineFlowVar` can be read immediately using the `^` operator. This line displays the input which was read by `readLine`. |





Save *Listing 6.8* as `listing5.nim` then compile and run it. The application will wait until you enter some input into the terminal. It will only check whether input has been entered every 5 seconds.


Using the `FlowVar` type is straightforward. Reading the value contained inside it is done using the `^` operator, keep in mind that using this operator will block the thread it is used in until the `FlowVar` it is called on contains a value. You can check whether a `FlowVar` contains a value using the `isReady` procedure. *Listing 6.8* checks whether the `lineFlowVar` variable contains a value periodically, every 5 seconds.


Keep in mind that *Listing 6.8* is meant to demonstrate how the `FlowVar[T]` works. The example is not meant to be practical as the program will only check for input every 5 seconds.


Of course, in this case you may just as well call `readLine` on the main thread since there is nothing else running on it. The idea is that you replace the `sleep(5000)` statement with some other procedure which does some useful work on the main thread, for example you may draw your application’s user interface or call the asynchronous I/O event loop’s `poll` procedure like in *Chapter 3*.





6.2.3  Exceptions in threads
----------------------------



The way in which exceptions behave in separate threads may be surprising. When a thread crashes with an unhandled exception, the application will crash with it. It doesn’t matter whether you read the value of the `FlowVar` or not. *Listing 6.9* shows this behaviour in action.




Listing 6.9. Exceptions in a spawned procedure.




```
import threadpool

proc crash(): string =
  raise newException(Exception, "Crash")

let lineFlowVar = spawn crash()
sync()
```



Save *Listing 6.9* as `listing6.nim` then compile and run it. You should see a traceback in the output, pointing you to the `raise` statement in the `crash` procedure.





> Tip The `raises` pragma |
| The `{.raises.}` pragma can be used to ensure that your threads handle all exceptions. To make use of it, you can define the `crash` procedure like so: `proc crash(): string {.raises: [].} = …`. |



In summary, the simplicity of both passing arguments to the spawned procedure and receiving the procedure’s result, makes `spawn` good for tasks which have a relatively short run time. Such tasks typically produce results at the end of their execution and as such don’t need to communicate with other threads until their execution stops.


For long-running tasks which need to communicate with other threads periodically, the `createThread` procedure defined in the `threads` module should be used instead.




  


[[19]](#d5e6428) <http://nim-lang.org/docs/threads.html>




[[20]](#d5e6432) <http://nim-lang.org/docs/threadpool.html>







6.3  Parsing data
=================



Now that you know how to use threads in Nim, let’s have a look at a practical example of how they can be used. The example shown in this section will involve parsers.


Parsers can benefit greatly from parallelisation, by being able to make use of all CPU cores they can parse data much more efficiently. So in addition to learning about how parsers work this section will show you a practical use case for parallelisation, and more importantly how to utilize Nim’s concurrency and parallelism features for such a use case.


There is a very large amount of data generated every day; the data comes from many different sources and is intended for many different applications. Computers are very useful tools for the processing of data. But in order for that data to be consumed, the format that the data is stored in must be understood by the computer.


A *parser* is a component of software that takes input data and builds a data structure out of it. The data is typically in the form of text. In *Chapter 3* you have looked at the JSON data format, and how it was parsed using the `json` module into a data structure which could then be queried for specific information.


There often comes a time when you are faced with the task of writing a custom parser for a simple data format. There are many ways such a task can be tackled in Nim.


In this section I will show you how to write a parser for Wikipedia’s page view data. [[21]](#ftn.d5e6783) This data is useful for many different applications, but the aim of this section is to create an application which will find the most popular page in the English Wikipedia. Throughout this section you will:



* Learn the structure and format of the Wikipedia page count files.
* Use different techniques to write a parser for the page counts format.
* Read large files by breaking them up into conveniently-sized smaller *chunks* or fragments.






> Note Wikipedia API |
| Wikipedia recently introduced a Pageview API [[22]](#ftn.d5e6797) which supplements the raw page view data. This API makes finding the most popular page in the English Wikipedia much easier. If you are writing an application which needs to find the most popular pages on Wikipedia specifically, then you may want to use the API instead. Parsing the raw data manually is less efficient but you will hopefully find the example applicable to other tasks. |



At the end of this section I will also show you how to parallelise the parser. This will allow it to perform better on systems with multi-core CPUs.




6.3.1  Understanding the Wikipedia page counts format
-----------------------------------------------------



The raw page count data can be downloaded from the following URL: <https://dumps.wikimedia.org/other/pagecounts-all-sites/>.


The data files are organised into a specific year and month. For example the page count data for January 2016 is available at the following URL: <https://dumps.wikimedia.org/other/pagecounts-all-sites/2016/2016-01/>. The page count data is then further subdivided into a day and hour. Each file located in the URL above represents the visitors within a single hour. The files are all gzipped in order to reduce their size.


Download the following file and then extract it: <https://dumps.wikimedia.org/other/pagecounts-all-sites/2016/2016-01/pagecounts-20160101-050000.gz>





> Note For Windows users |
| On Windows, you may need to install 7zip or another application for extracting gzipped archives. |



The file may take a while to download depending on your internet speed. This file in particular is around 92MB before extraction, after it is extracted it is around 428MB so it is a fairly large file. The parser will need to be as efficient as possible in order to parse that file in a timely manner.


The file is filled with lines of text separated by a newline character, each line of text consists of the following 4 fields separated by a space:




```
domain_code page_title count_views total_response_size
```


The `domain_code` contains an abbreviated domain name, for example "en.wikipedia.org" is abbreviated as `en`. The `page_title` contains the title of the page requested, for example `Dublin` for "http://en.wikipedia.org/wiki/Dublin". The `count_views` contains the number of times the page has been viewed within the hour. Finally, the `total_response_size` contains the total response size caused by the requests for the page.


For example, the line:




```
en Nim_(programming_language) 1 70231
```


Means that there was 1 request to "http://en.wikipedia.org/wiki/Nim\_(programming\_language)" which accounted in total for 70231 response bytes.


The file which I asked you to download is one of the smaller files from January. It contains data about the pages visited on Wikipedia from the 1st of January 2016 4:00am UTC to the 1st of January 2016 5:00am UTC.





6.3.2  Parsing the Wikipedia page counts format
-----------------------------------------------



There are many different options when it comes to parsing the data format described above. In this subsection I will implement a parser using two different methods: regular expressions and the `parseutils` module.


**Using regular expressions**


A common way to parse data is using regular expressions. If you have ever dealt with string processing in any way then it is likely that you have come across them. Regular expressions are very popular and in many cases when developers are faced with a task which requires them to parse a string, they immediately jump to using regular expressions.


Regular expressions are by no means a magical solution to every parsing problem. For example, writing a regular expression to parse arbitrary HTML is virtually impossible. But for the task of parsing a simple data format like the one defined above, regular expressions work well.


Explaining regular expressions in depth is beyond the scope of this chapter. If you are not familiar with them, you are encouraged to read up on them online.


Regular expressions are supported in Nim via the `re` module. It defines procedures and types for using regular expressions to parse and manipulate strings.






[Caution]  External dependency 
The `re` module is an impure module which means that it depends on an external C library. In `re`'s case, the library is called PCRE and it must be installed alongside your application in order for your application to function properly. 



Let’s focus on parsing a single line first. *Listing 6.10* shows how to do that with the `re` module.




Listing 6.10. Parsing data with the `re` module




```
import re   ❶

let pattern = re"([^\s]+)\s([^\s]+)\s(\d+)\s(\d+)"    ❷

var line = "en Nim_(programming_language) 1 70231"
var matches: array[4, string]   ❸
let start = find(line, pattern, matches)   ❹
doAssert start == 0             ❺
doAssert matches[0] == "en"                           ❻
doAssert matches[1] == "Nim_(programming_language)"   ❻
doAssert matches[2] == "1"                            ❻
doAssert matches[3] == "70231"                        ❻
echo("Parsed successsfully!")
```




|  |  |
| --- | --- |
| [❶](#CO6-1) | The `re` module defines the `find` procedure used below. |
| [❷](#CO6-2) | A new regex pattern is constructed using the `re` constructor. |
| [❸](#CO6-3) | This `matches` array will hold the matched substrings of `line`. |
| [❹](#CO6-4) | The `find` procedure is used to find matching substrings as specified by the subgroups in the regex. The substrings are put into the `matches` array. |
| [❺](#CO6-5) | The return value indicates the starting position of the matching string, `-1` is returned if no match was made. |
| [❻](#CO6-6) | The first matching group will capture the substring `"en"`, followed by the second matching group which will capture `"Nim_(programming_language)"` and so on. |





 





|  |  |
| --- | --- |
| [Warning] | The `re` constructor |
| Constructing a regular expression is an expensive operation, when performing multiple regex matches with the same regular expression make sure to reuse the value returned by the `re` constructor! |



Save *Listing 6.10* as `listing7.nim` then compile and run it. The program should compile and run successsfully. The program should display "Parsed successfully!".





> Tip PCRE problems |
| If the program exits with an error similar to `could not load: pcre.dll` then you are missing the PCRE library and must install it. |



The code for parsing strings with regular expressions is straightforward. As long as you know how to create regular expressions you should have no trouble using it.


The `re` module also includes other procedures for parsing as well as manipulating strings. You can replace matched substrings using the `replace` procedure for example. Take a look at the documentation for the `re` module for more information. [[23]](#ftn.d5e6900)


**Parsing the data manually using `split`**


You can also parse data manually in many different ways. This has multiple advantages but also a few disadvantages. The biggest advantage over using regular expressions is that your application will have no dependency on the PCRE library. Manual parsing also gives you greater more precise control over the parsing process. In some cases, the biggest disadvantage is that it takes more code to parse data manually.


For such a simple data format, you can use the `split` procedure defined in the `strutils` module. *Listing 6.11* shows how `split` can be used to parse "en Nim\_(programming\_language) 1 70231".




Listing 6.11. Parsing using `split`




```
import strutils   ❶

var line = "en Nim_(programming_language) 1 70231"
var matches = line.split()       ❷
doAssert matches[0] == "en"      ❸
doAssert matches[1] == "Nim_(programming_language)"   ❸
doAssert matches[2] == "1"       ❸
doAssert matches[3] == "70231"   ❸
```




|  |  |
| --- | --- |
| [❶](#CO7-1) | The `strutils` module defines the `split` procedure. |
| [❷](#CO7-2) | By default the `split` procedure splits the string when it finds whitespace. The returned sequence will be `@["en", "Nim_(programming_language)", "1", "70231"]`. |
| [❸](#CO7-3) | The resulting `matches` variable’s contents are the same as before. |





This will work very well for this use case. But for more complex data formats you may wish to use something that is more flexible. The most flexible way to parse strings is to iterate over every character in that string using a while loop. This method of parsing is also very verbose but is useful in certain circumstances, for example when parsing more complex data formats like HTML. Nim provides a `parseutils` module which defines procedures that make parsing using such methods much easier.


**Parsing the data manually using `parseutils`**


*Listing 6.12* shows how the `parseutils` module can be used to parse "en Nim\_(programming\_language) 1 70231".




Listing 6.12. Parsing using `parseutils`




```
import parseutils     ❶

var line = "en Nim_(programming_language) 1 70231"

var i = 0             ❷
var domainCode = ""   ❸
i.inc parseUntil(line, domainCode, {' '}, i)   ❹
i.inc                 ❻
var pageTitle = ""    ❸
i.inc parseUntil(line, pageTitle, {' '}, i)    ❹
i.inc                 ❻
var countViews = 0    ❸
i.inc parseInt(line, countViews, i)            ❺
i.inc                 ❻
var totalSize = 0     ❸
i.inc parseInt(line, totalSize, i)             ❺


doAssert domainCode == "en"
doAssert pageTitle == "Nim_(programming_language)"
doAssert countViews == 1
doAssert totalSize == 70231
```




|  |  |
| --- | --- |
| [❶](#CO8-1) | Import `parseutils` which defines `parseUntil`. |
| [❷](#CO8-2) | Define a counter to keep track of the position in the string that the program is currently at. |
| [❸](#CO8-3) | Define a string or int variable where the parsed token will be stored. |
| [❹](#CO8-4) | Copy characters starting at index `i` from string `line` to the string specified in the second argument until `line[i] == ' '`. The returned value is the amount of characters captured. |
| [❺](#CO8-10) | Parse an int starting at index `i` in string `line`. The parsed int is stored in the second argument. Returned value is the amount of characters captured. |
| [❻](#CO8-5) | Skip whitespace character by simply incrementing `i`. |





The code in *Listing 6.12* is far more complex than the previous listing, but allows for far greater flexibility. The `parseutils` module defines many other procedures which are useful for parsing. They are all mostly just convenient wrappers over a while loop. For example the equivalent code of `i.inc parseUntil(line, domainCode, {' '}, i)` is the following:




```
while line[i] != ' ':
  domainCode.add(line[i])
  i.inc
```


Because of the flexibility of this parser, the code is able to parse the last two fields into integers in one single step. Instead of having to first separate the fields and then parse the integer separately which would be inefficient.


In summary, the `split` procedure looks the simplest out of all of them, but it is actually slower than `parseutils`. This is because it needs to create a sequence and new strings to hold the matches. In comparison the parsing code which uses `parseutils` only needs to create 2 new strings and 2 new integers, there is no overhead associated with the creation of a sequence.


The regex parsing code is also simpler, but it suffers from the PCRE dependency and is also slower than the `parseutils` parser.


This makes the `parseutils` parser the best for this use case, even though it is slightly more complex and significantly more verbose. Its speed will come in handy when parsing the 7,156,099 lines contained inside the `pagecounts-20160101-050000` file.





6.3.3  Processing each line of a file efficiently
-------------------------------------------------



The Wikipedia page count files are large. Each measures around 500MB and contains around 10 million lines of data. The `pagecounts-20160101-050000` which I asked you to download measures 428MB and contains 7,156,099 lines of page count data. It is one of the smallest in January, I picked it to save you some bandwidth.


In order to parse this file efficiently you will need to consume the file in fragments. Reading the full file into your program’s memory would consume at least 428MB of RAM, the actual consumption would likely be far larger due to various overheads. That is why it is a good idea to read large files by breaking them up into conveniently-sized smaller fragments, otherwise known as *chunks*.




### Using an iterator to read a file in fragments



Nim defines an iterator which iterates over each line in a file. This iterator does not need to copy the full file’s contents into the program’s memory, which makes it very efficient. The iterator is called `lines` and is defined in the `system` module.


*Listing 6.13* shows how the `lines` iterator can be used to read lines from the `pagecounts-20160101-050000` file.




Listing 6.13. Iterating over each line in a file




```
import os   ❶
proc readPageCounts(filename: string) =   ❷
  for line in filename.lines:   ❸
    echo(line)   ❹

when isMainModule:   ❺
  const file = "pagecounts-20160101-050000"   ❻
  let filename = getCurrentDir() / file   ❼
  readPageCounts(filename)   ❽
```




|  |  |
| --- | --- |
| [❶](#CO9-1) | The `os` module defines the `getCurrentDir` procedure. |
| [❷](#CO9-2) | Define a `readPageCounts` procedure which takes the file name of the page counts file as an argument. |
| [❸](#CO9-3) | Iterate through each line in the file located at `filename` using the `lines` iterator. |
| [❹](#CO9-4) | Display each line that was read. |
| [❺](#CO9-5) | Check whether this module is being compiled as the main module. |
| [❻](#CO9-6) | Define a constant `file` and assign it the name of the page counts file. |
| [❼](#CO9-7) | Define a variable `filename` and assign it the path of the program’s current working directory joined with `file`. The `/` operator is defined in the `os` module and is used to concatenate file paths. |
| [❽](#CO9-8) | Call the `readPageCounts` procedure and pass the value of the variable `filename` as an argument. |





Save *Listing 6.13* as `sequential_counts.nim` then compile and run it. The program will take around a minute to execute because it will display each line of the page counts file. You may terminate it by pressing Control together with the C key. As it runs you can observe the memory usage, it should remain low.





### Parsing each line



Now you can simply add the parsing code from the previous section to the code in *Listing 6.13*. *Listing 6.14* shows how the parser can be integrated into *Listing 6.13*, changes are highlighted in bold.




Listing 6.14. Parsing each line in a file




```
import os**, parseutils**

**proc parse(line: string, domainCode, pageTitle: var string,
 countViews, totalSize: var int) =**   ❶
  **var i = 0**
  **domainCode.setLen(0)**   ❷
  **i.inc parseUntil(line, domainCode, {' '}, i)**
  **i.inc**
  **pageTitle.setLen(0)**    ❷
  **i.inc parseUntil(line, pageTitle, {' '}, i)**
  **i.inc**
  **countViews = 0**         ❸
  **i.inc parseInt(line, countViews, i)**
  **i.inc**
  **totalSize = 0**          ❸
  **i.inc parseInt(line, totalSize, i)**

proc readPageCounts(filename: string) =
  **var domainCode = ""**
  **var pageTitle = ""**
  **var countViews = 0**
  **var totalSize = 0**
  for line in filename.lines:
    **parse(line, domainCode, pageTitle, countViews, totalSize)**   ❹
    **echo("Title: ", pageTitle)**           ❺

when isMainModule:
  const file = "pagecounts-20160101-050000"
  let filename = getCurrentDir() / file
  readPageCounts(filename)
```




|  |  |
| --- | --- |
| [❶](#CO10-1) | The variables in which the parsed tokens are stored are passed by reference, this is more efficient because new strings do not have to be allocated for each call to `parse`. |
| [❷](#CO10-2) | The length of the string is reset to 0. This is much more efficient than assigning `""` because that allocates a new string. |
| [❸](#CO10-4) | The integer variables are simply reset to 0. |
| [❹](#CO10-6) | Call the `parse` procedure and pass it the current `line` together with variables where tokens can be stored. |
| [❺](#CO10-7) | Display the title of each page that was found in the page counts file. |





Replace the code in `sequential_counts.nim` with the code in *Listing 6.14*. *Listing 6.15* shows what some of the output from `sequential_counts.nim` may look like.




Listing 6.15. The output of `sequential_counts.nim`




```
...
Title: List_of_digital_terrestrial_television_channels_(UK)
Title: List_of_diglossic_regions
Title: List_of_dignitaries_at_the_state_funeral_of_John_F._Kennedy
Title: List_of_dimensionless_quantities
Title: List_of_diners
Title: List_of_dinosaur_genera
Title: List_of_dinosaur_specimens_with_nicknames
Title: List_of_dinosaurs
...
```



The code employs a number of optimisations. In general the biggest slowdowns in Nim applications are a result of too many variables being allocated and deallocated. The `parse` procedure could return the parsed tokens but that would result in a new string being allocated each iteration. Instead the `parse` procedure accepts a mutable reference to 2 strings and 2 ints, which it then fills with the parsed tokens. For an input which takes around 9.3 seconds to complete without the optimisation, it takes around 7.8 seconds to complete with the optimisation. Which is a difference of 1.5 seconds. The use of `setLen` is another optimization, it ensures that the string is not reallocated but is instead reused. The `parse` procedure is executed at least 7 million times, so any tiny optimisation creates massive gains in total execution speed.


The profiler that you will be introduced to later in this book can show you procedures in your program which are executed often. You may then employ optimisations similar to the ones described here.





### Finding the most popular article



Now that the parsing code has been introduced, all that is left is to find the most popular article on the English Wikipedia. *Listing 6.16* shows the finished `sequential_counts` application, latest changes are shown in bold.




Listing 6.16. The finished `sequential_counts.nim`




```
import os, parseutils

proc parse(line: string, domainCode, pageTitle: var string,
    countViews, totalSize: var int) =
  var i = 0
  domainCode.setLen(0)
  i.inc parseUntil(line, domainCode, {' '}, i)
  i.inc
  pageTitle.setLen(0)
  i.inc parseUntil(line, pageTitle, {' '}, i)
  i.inc
  countViews = 0
  i.inc parseInt(line, countViews, i)
  i.inc
  totalSize = 0
  i.inc parseInt(line, totalSize, i)

proc readPageCounts(filename: string) =
  var domainCode = ""
  var pageTitle = ""
  var countViews = 0
  var totalSize = 0
  **var mostPopular = ("", "", 0, 0)**   ❶
  for line in filename.lines:
    parse(line, domainCode, pageTitle, countViews, totalSize)
    **if domainCode == "en" and countViews > mostPopular[2]:**   ❷
      **mostPopular = (domainCode, pageTitle, countViews, totalSize)**   ❸

  **echo("Most popular is: ", mostPopular)**

when isMainModule:
  const file = "pagecounts-20160101-050000"
  let filename = getCurrentDir() / file
  readPageCounts(filename)
```




|  |  |
| --- | --- |
| [❶](#CO11-1) | Define a variable to hold the information about the most popular page. This is defined as a tuple which stores the 4 parsed fields. |
| [❷](#CO11-2) | Check whether the current line contains information about a page from the English Wikipedia and whether its view count is greater than that of the currently most popular page. |
| [❸](#CO11-3) | If it is then save it as the new most popular page. |





Replace the contents of `sequential_counts.nim` with code in *Listing 6.16*, then compile in release mode and run it. After a few seconds you should see output similar to the one in *Listing 6.17*.





|  |  |
| --- | --- |
| [Caution] | Release mode |
| Ensure that you compile `sequential_counts.nim` in release mode, by passing the `-d:release` flag to the Nim compiler. Without that flag the execution time of the application will be significantly higher. |





Listing 6.17. Output for `sequential_counts.nim`




```
Most popular is: (Field0: en, Field1: Main_Page, Field2: 271165, Field3: 4791147476)
```



The most popular page in the English Wikipedia is in fact the Main Page! This makes a lot of sense, and while it’s obvious in hindsight it’s trivial to edit the code you have written to find more interesting statistics. I now challenge you to edit `sequential_counts.nim` and play around with the data. You can try finding the top 10 most popular pages in the English Wikipedia, or you can download different page count files and compare the results.


You should now have a good idea about how to parse data effectively. You will have learned what bottlenecks to look out for in your Nim applications and how to fix them. The next step is to parallelise this parser so that its execution time is even lower on multi-core CPUs.





  


[[21]](#d5e6783) <https://wikitech.wikimedia.org/wiki/Analytics/Data/Pagecounts-all-sites>




[[22]](#d5e6797) <https://wikitech.wikimedia.org/wiki/Analytics/PageviewAPI>




[[23]](#d5e6900) <http://nim-lang.org/docs/re.html>







6.4  Parallelising a parser
===========================



In order for the program to be parallel, it must make use of threads. As mentioned previously there are two ways that threads can be created in Nim. Either using the `threads` module, or using the `threadpool` module. Both will work, but the `threadpool` module is more appropriate for this program.




6.4.1  Measuring the execution time of `sequential_counts`
----------------------------------------------------------



Before starting to parallelise the code, let’s measure how long `sequential_counts` takes to execute.


This can be done very easily on Unix-like operating systems by using the `time` command. Executing `time ./sequential_counts` should output `sequential_counts`'s execution time. On a Macbook Pro with an SSD and a dual core 2.7GHz Intel Core i5 CPU which includes hyperthreading, the execution time is about 2.8 seconds.


On Windows you will need to open a new Windows PowerShell window, then use the `Measure-Command` command to measure the execution time. Executing `Measure-Command {./sequential_counts.exe}` should output `sequential_counts`'s execution time.


The program currently runs in a single thread and is very CPU intensive. This means that its speed can be significantly improved by making it parallel.





6.4.2  Parallelising `sequential_counts`
----------------------------------------



Copy `sequential_counts.nim` to `parallel_counts.nim`. This will be the file that will soon become parallel.


So how should the `threadpool` module be used to parallelise this code? You may be tempted to `spawn` the `parse` procedure, but this cannot work because it needs `var` parameters which cannot safely be passed to a spawned procedure. It also wouldn’t help much because a single call to `parse` is relatively quick.


Before you can parallelise this code, you must first change the way that the page counts file is read. Instead of reading each line separately, you need to read the file in large fragments. There are some factors to consider when reading the file like that, one of them is the fragment size to read.


Consider the following scenario. The page counts file begins with the following:




```
en Main_Page 123 1234567
en Nim_(programming_language) 100 12415551
```


If the fragment size is so small that only `"en Main_Page"` is read then the program will fail, because the size of the fragment is insufficient. In order for this to be solved, the fragment size simply needs to be large enough.


Another problem is that in most cases, the fragment will contain valid data at the start but it will end with a line that was not read fully! For example `"en Main_Page 123 1234567\nen Nim_"`. This data will need to be split after every occurrence of `"\n"` (new line), and each line will need to be parsed separately. The last line will lead to an error, because it’s not full. The solution is to find where the last line ends, then defer the parsing of the line which has not been fully read to the next time a fragment of the file is read.


Here is how `parallel_counts.nim` should work:



* Instead of reading lines, a large fragment of text should be read.
* A new procedure called `parseChunk` should be created.
* The `parseChunk` procedure should receive a fragment of text, go through each line and pass it to the `parse` procedure.
* At the same time it should check which of the parsed pages are the most popular.
* The `parseChunk` procedure should be spawned. A *slice* of the fragment should be passed to `parseChunk`, the slice should not contain any incomplete lines.
* The incomplete line should be saved. Once the next fragment is read, the incomplete line should be prepended to the newly ready fragment.






> Note Terminology |
| The term *chunk* is synonymous with the term *fragment*, and throughout this chapter both will be used interchangeably. |



*Listing 6.18*, *Listing 6.19*, and *Listing 6.20* show different sections of a `parallel_counts.nim` file with an implementation which is similar to the one described above.





6.4.3  Type definitions and the `parse` procedure
-------------------------------------------------



*Listing 6.18* starts with the top of the file where there is not much change. This includes the import statement, some new type definitions and the original `parse` procedure. A new `Stats` type is defined to store page count statistics about a specific page, this type will be used to store the most popular page in each spawned procedure. The `Stats` type will be returned from the spawned procedure, this means that it must be a `ref` type as `spawn` currently cannot spawn procedures which return custom value types. A new procedure called `newStats` is also defined, it simply constructs a new empty `Stats` object. Together with that is the definition of `$` which simply converts a `Stats` type to a string.




Listing 6.18. The top section of `parallel_counts.nim`




```
import os, parseutils, threadpool, strutils   ❶

type
  Stats = ref object               ❷
    domainCode, pageTitle: string  ❸
    countViews, totalSize: int     ❸

proc newStats(): Stats =           ❹
  Stats(domainCode: "", pageTitle: "", countViews: 0, totalSize: 0)

proc `$`(stats: Stats): string =   ❺
  "(domainCode: $#, pageTitle: $#, countViews: $#, totalSize: $#)" % [
    stats.domainCode, stats.pageTitle, $stats.countViews, $stats.totalSize
  ]

proc parse(line: string, domainCode, pageTitle: var string,
    countViews, totalSize: var int) =          ❻
  if line.len == 0: return
  var i = 0
  domainCode.setLen(0)
  i.inc parseUntil(line, domainCode, {' '}, i)
  i.inc
  pageTitle.setLen(0)
  i.inc parseUntil(line, pageTitle, {' '}, i)
  i.inc
  countViews = 0
  i.inc parseInt(line, countViews, i)
  i.inc
  totalSize = 0
  i.inc parseInt(line, totalSize, i)
```




|  |  |
| --- | --- |
| [❶](#CO12-1) | The `threadpool` module is required for `spawn` and the `strutils` module is required for the `%` operator. |
| [❷](#CO12-2) | Define a new `Stats` type which will hold information about a page’s statistics. The type has to be defined as a `ref` because a procedure which returns a non-ref type cannot be spawned! |
| [❸](#CO12-3) | The `Stats` type defines fields for each of the parsed tokens. |
| [❹](#CO12-5) | Define a new procedure called `newStats` which acts as a constructor for the `Stats` type. |
| [❺](#CO12-6) | Define a `$` operator for the `Stats` type so that it can be converted to a string easily. In practice this means that `echo` can display it. |
| [❻](#CO12-7) | The `parse` procedure is the same. |








6.4.4  The `parseChunk` procedure
---------------------------------



*Listing 6.19* shows the middle section of the `parallel_counts.nim` file. It defines a new procedure called `parseChunk`, which takes a string parameter called `chunk` and returns the most popular English Wikipedia page in that fragment. The fragment consists of multiple lines of page count data. The procedure begins by initialising the `result` variable, the return type is a `ref` type which must be initialised so that it’s not `nil`. The rest of the procedure is similar to what the `readPageCounts` procedure looks like in the `sequential_counts.nim` file. It defines 4 variables to store the parsed tokens, then it iterates through the lines in the `chunk` using the `splitLines` iterator and parses each of the lines.




Listing 6.19. The middle section of `parallel_counts.nim`




```
proc parseChunk(chunk: string): Stats =   ❶
  result = newStats()    ❷
  var domainCode = ""    ❸
  var pageTitle = ""     ❸
  var countViews = 0     ❸
  var totalSize = 0      ❸
  for line in splitLines(chunk):          ❹
    parse(line, domainCode, pageTitle, countViews, totalSize)        ❺
    if domainCode == "en" and countViews > result.countViews:        ❻
      result = Stats(domainCode: domainCode, pageTitle: pageTitle,   ❼
                     countViews: countViews, totalSize: totalSize)
```




|  |  |
| --- | --- |
| [❶](#CO13-1) | The `parseChunk` procedure is very similar to what the `readPageCounts` procedure looks like in `sequential_counts.nim`. |
| [❷](#CO13-2) | Initialise the `result` variable with a new value of the `Stats` type. |
| [❸](#CO13-3) | Create variables to store the parsed tokens. |
| [❹](#CO13-7) | Iterate over ever line in `chunk`. |
| [❺](#CO13-8) | Call the `parse` procedure on each line inside the `chunk` to parse into the 4 fields: `domainCode`, `pageTitle`, `countViews`, and `totalSize`. |
| [❻](#CO13-9) | Check if the parsed page is in the English Wikipedia and whether it got more views than the page stored in `result`. |
| [❼](#CO13-10) | If that is the case, then `result` is assigned the parsed page. |








6.4.5  The parallel `readPageCounts` procedure
----------------------------------------------



*Listing 6.20* shows the `readPageCounts` procedure which has been modified significantly since the last time you saw it in *Listing 6.16*. It now takes an optional parameter called `chunkSize` which determines how many characters it should read each iteration. The procedure’s implementation is what differs most, the file is opened manually using the `open` procedure and what follows are definitions of variables which are required to properly store the results of the fragment reading process.


The fragment reading process is complicated by the fact that the code needs to ensure it keeps track of unfinished lines. It does so by moving backwards through the contents of `buffer`, which stores the fragment temporarily, until it finds a newline character. The `buffer` string is then sliced from the start of the fragment to the end of the last full line in the fragment. The resulting slice is then passed to the `parseChunk` procedure which is spawned in a new thread using `spawn`.


The end of the fragment which has not yet been parsed is then moved to the beginning of the `buffer`. In the next iteration, the length of the characters which will be read will be `chunkSize` minus the length of the buffer which was not read in the last iteration.




Listing 6.20. The bottom section of `parallel_counts`.nim




```
proc readPageCounts(filename: string, chunkSize = 1_000_000) =          ❶
  var file = open(filename)    ❷
  var responses = newSeq[FlowVar[Stats]]()   ❸
  var buffer = newString(chunkSize)          ❹
  var oldBufferLen = 0         ❺
  while not endOfFile(file):   ❻
    let reqSize = chunksize - oldBufferLen   ❼
    let readSize = file.readChars(buffer, oldBufferLen, reqSize) + oldBufferLen   ❽
    var chunkLen = readSize    ❾

    while chunkLen >= 0 and buffer[chunkLen - 1] notin NewLines:         ❿
      chunkLen.dec

    responses.add(spawn parseChunk(buffer[0 .. <chunkLen]))              ⓫
    oldBufferLen = readSize - chunkLen
    buffer[0 .. <oldBufferLen] = buffer[readSize - oldBufferLen .. ^1]   ⓬

  var mostPopular = newStats()
  for resp in responses:    ⓭
    let statistic = ^resp   ⓮
    if statistic.countViews > mostPopular.countViews:   ⓯
      mostPopular = statistic

  echo("Most popular is: ", mostPopular)

  file.close()   ⓰

when isMainModule:
  const file = "pagecounts-20160101-050000"
  let filename = getCurrentDir() / file
  readPageCounts(filename)
```




|  |  |
| --- | --- |
| [❶](#CO14-1) | The `readPageCounts` procedure now includes a `chunkSize` parameter with a default value of `1_000_000`. The underscores help readability and are ignored by Nim. |
| [❷](#CO14-2) | The `open` procedure is now used to open a file, it returns a `File` object which is stored in the `file` variable. |
| [❸](#CO14-3) | Define a new `responses` sequence to hold the FlowVar objects which will be returned by `spawn`. |
| [❹](#CO14-4) | Define a new `buffer` string of length equal to `chunkSize`. Fragments will be stored here. |
| [❺](#CO14-5) | Define a variable to store the length of the last buffer which was not parsed. |
| [❻](#CO14-6) | Loop until the full file is read. |
| [❼](#CO14-7) | Calculate the amount of characters that needs to be read. |
| [❽](#CO14-8) | Use the `readChars` procedure to read the `reqSize` amount of characters. This procedure will place the characters that it reads starting at `oldBufferLen`, which will ensure that the old buffer is not overwritten. The `oldBufferLen` is added because that is length of the old buffer which has been read previously. |
| [❾](#CO14-9) | Create a variable to store the fragment length that will be parsed. |
| [❿](#CO14-10) | Decrease the `chunkLen` variable until `chunkLen - 1` points to any newline character. |
| [⓫](#CO14-11) | Create a new thread to execute the `parseChunk` procedure, pass a slice of the `buffer` which contains a fragment which can be parsed. Add the `FlowVar[string]` returned by `spawn` to the list of responses. |
| [⓬](#CO14-12) | Assign the part of the fragment which was not parsed to the beginning of `buffer`. |
| [⓭](#CO14-13) | Iterate through each response. |
| [⓮](#CO14-14) | Block the main thread until the response can be read, then save the response value in the variable `statistics`. |
| [⓯](#CO14-15) | Check if the most popular page in a particular fragment is more popular than the one saved in the `mostPopular` variable. If it is, then overwrite the `mostPopular` variable with it. |
| [⓰](#CO14-16) | Ensure that the file object is closed. |





The parallel version is unfortunately more complex. The complexity is mostly restricted to the `readPageCounts` procedure, where the algorithm for reading the file in fragments adds great complexity to the program. But in terms of the line count, the parallel version is only about twice as long.





6.4.6  The execution time of `parallel_counts`
----------------------------------------------



Merge *Listing 6.18*, *Listing 6.19*, and *Listing 6.20* into a single `parallel_counts.nim` file. Then compile and run the program. Make sure to pass both the `--threads:on` flag as well as the `-d:release` flag to Nim when compiling. Measure the execution time using the techniques described above.


On a Macbook Pro with an SSD and a dual core 2.7GHz Intel Core i5 CPU which includes hyperthreading, the execution time is about 1.2 seconds which is a decrease in execution time of over 50% in comparison to the 2.8 seconds that the sequential version took to execute. That is a large difference!


On Unix-like systems, the `time` command allows us to verify that the parallel version is in fact parallel by looking at its CPU usage. For example, `./parallel_counts 4.30s user 0.25s system 364% cpu 1.251 total` which shows that `parallel_counts` was using 364% of the available CPU. In comparison `sequential_counts` almost always shows around 99% CPU usage.


Now that you saw how to parallelise a parser you should have a better idea about how to parallelise Nim code in general. The last sections of this chapter will teach you about race conditions and how to avoid them.






6.5  Dealing with race conditions
=================================



You don’t typically need to worry about race conditions when writing concurrent code in Nim. Because of the restriction that Nim puts on GC-safe procedures: memory belonging to another thread cannot be accessed in a spawned procedure or a procedure marked using the `{.thread.}` pragma.


A race condition occurs when two or more threads attempt to read and write to a shared resource at the same time. Such behaviour can result in unpredictable results that often are difficult to debug. This is one of the reasons why Nim prevents the sharing of some resources between threads. Nim instead prefers data to be shared using alternative methods such as *channels* which prevent race conditions.


Sometimes these methods are not appropriate for certain use cases, for example when lots of data needs to be modified by the thread. Because of this Nim also supports shared memory, sharing memory via global variables is easy as long as you only want to share value types. Sharing reference types is much harder because you must make use of Nim’s manual memory management procedures.





|  |  |
| --- | --- |
| [Warning] | Shared memory |
| Using shared memory is risky because it increases the chances for race conditions in your code. Coupled with the fact that you must manage the memory yourself, I advise you to only use it if you are certain that it is required and when you know what you are doing. |



*Listing 6.21* implements a simple program which increments the value of a global variable inside two threads that are running in parallel. The result is a race condition.




Listing 6.21. Race condition with shared memory




```
import threadpool         ❶

var counter = 0           ❷

proc increment(x: int) =
  for i in 0 .. <x:       ❸
    var value = counter   ❹
    value.inc   ❺
    counter = value       ❻

spawn increment(10_000)   ❼
spawn increment(10_000)   ❼
sync()          ❽
echo(counter)   ❾
```




|  |  |
| --- | --- |
| [❶](#CO15-1) | The `threadpool` module defines the `spawn` procedure. |
| [❷](#CO15-2) | Define a global variable called `counter`. |
| [❸](#CO15-3) | Iterate from `0` to `x-1`. |
| [❹](#CO15-4) | Define a new local variable called `value` and assign it the value of `counter`. |
| [❺](#CO15-5) | Increment `value`. |
| [❻](#CO15-6) | Set the value of the global `counter` variable to the value of `value`. |
| [❼](#CO15-7) | Spawn two new threads which will call the `increment` procedure with `10_000` as the argument. |
| [❽](#CO15-9) | Wait until all the threads are finished. |
| [❾](#CO15-10) | Display the value of the counter. |





In this case the `increment` procedure is GC-safe because the global variable `counter` it accesses is of type `int` which is a value type. The `increment` procedure increments the global `counter` variable `x` amount of times. The procedure is spawned twice, which means that there will be two `increment` procedures executing at the same time. The fact that they are both reading, incrementing and then writing the incremented value to the global `counter` variable in discrete steps, means that some increments may be missed.





> Tip Sharing memory which must be allocated on the heap |
| Value types such as integers can exist on the stack (or in the executable’s data section if the value is stored in a global variable), but reference types such as `string`, `seq[T]` and `ref T` cannot. Nim supports the sharing of reference types, but it will not manage the memory for you. This may change in a future version of Nim, but currently you must use a procedure called `allocShared` defined in the `system` module to allocate shared memory manually. *Chapter 8* will explain this in more detail. |



Save *Listing 6.21* as `race_condition.nim`, then compile and run it. Run it a couple of times and note the results. The results should appear random, and should almost never display the expected value of `20000`. *Figure 6.5* shows what the execution of *Listing 6.21* looks like.




Figure 6.5. Synchronised and unsynchronised execution of *Listing 6.21*


![ch06 race cond](../Images/ch06_race_cond.png)

Preventing race conditions is very important because whenever a bug occurs due to a race condition, it is almost always nondeterministic. The bug will be very difficult to reproduce, and once it is reproduced debugging it will be even harder as the mere act of doing so may cause the bug to disappear.


Now that you know what race conditions are, let’s discuss ways to prevent them.




6.5.1  Using guards and locks to prevent race conditions
--------------------------------------------------------



Just like most languages, Nim provides synchronization mechanisms to ensure that resources are only used by a single thread at a time.


One of these mechanisms is a *lock*. It enforces limits on access to a resource, and it is usually paired with a single resource. Before that resource is accessed the lock is acquired and after the resource is accessed it is released. Other threads which try to access the same resource must attempt to acquire the same lock, and if the lock has already been acquired by another thread then the acquire operation will block the thread until the lock becomes released. This ensures that only one thread has access to the resource.


Locks work very well, but they are not assigned to any variables by default. They can be assigned using a *guard*. When a variable is guarded with a specific lock, the compile will ensure that the lock is locked before allowing access. Any other access will result in a compile-time error.


*Listing 6.22* shows how a new `Lock` together with a guard can be defined.




Listing 6.22. `unguarded_access.nim`




```
import threadpool, locks   ❶

var counterLock: Lock      ❷
initLock(counterLock)      ❸
var counter {.guard: counterLock.} = 0   ❹

proc increment(x: int) =
  for i in 0 .. <x:
    var value = counter
    value.inc
    counter = value

spawn increment(10_000)
spawn increment(10_000)
sync()
echo(counter)
```




|  |  |
| --- | --- |
| [❶](#CO16-1) | The `locks` module is now imported, it defines the `Lock` type and associated procedures. |
| [❷](#CO16-2) | A new `counterLock` of type `Lock` is defined. |
| [❸](#CO16-3) | The `counterLock` lock is initialised using the `initLock` procedure. |
| [❹](#CO16-4) | The `{.guard.}` pragma is used to ensure that the `counter` variable is protected by the `counterLock` lock. |





Save *Listing 6.22* as `unguarded_access.nim`, then compile it. The compilation should fail with `unguarded_access.nim(9, 17) Error: unguarded access: counter`. This is because the `counter` variable is protected by the guard which ensures that any access to `counter` must occur after the `counterLock` lock is locked. Let’s fix this error by locking the `counterLock` lock.




Listing 6.23. `parallel_incrementer.nim`




```
import threadpool, locks

var counterLock: Lock
initLock(counterLock)
var counter {.guard: counterLock.} = 0

proc increment(x: int) =
  for i in 0 .. <x:
    withLock counterLock:   ❶
      var value = counter
      value.inc
      counter = value

spawn increment(10_000)
spawn increment(10_000)
sync()
echo(counter)
```




|  |  |
| --- | --- |
| [❶](#CO17-1) | The code which accesses the `counter` variable is now inside a `withLock` section. This locks the lock and ensures that it is unlocked after the code under the section ends. |





Save the code in *Listing 6.23* as `parallel_incrementer.nim`, then compile and run it. The file should compile successfully and its output should always be `20000` which means that the race condition is fixed! The fact that the compiler verifies that every guarded variable is locked properly ensures the safe execution of the code. It also helps prevent bugs from appearing accidentally in the future, due to new code or existing code being changed.





6.5.2  Using channels so threads can send and receive messages
--------------------------------------------------------------



Despite all the efforts that Nim goes to in order to make locks as safe as possible, they may not always be the safest choice. And for some use cases they may simply be inappropriate, for example when threads share very few resources. Channels offer an alternative form of synchronization which allows threads to send and receive messages between each other.


A channel is an implementation of a *queue*, that is a FIFO or First-In-First-Out data structure. This means that the first value to be added to the channel will be the first one to be removed. The best way to visualise such a data structure is by imagining yourself queuing for food at a cafeteria, the first person to queue is also the first person to get their food. *Figure 6.6* shows a representation of a FIFO channel.




Figure 6.6. Representation of a FIFO channel


![ch06 fifo channel](../Images/ch06_fifo_channel.png)

Nim implements channels in the `channels` module of the standard library. This module is part of `system` and as such does not need to be explicitly imported. A channel is created as a global variable, allowing every thread to send and receive messages through it. Once a channel is defined it must be initialized, using the `open` procedure.


*Listing 6.24* defines and initialises a new `chan` variable, of type `Channel[string]`. You can specify any type inside the square brackets, including your own custom types.




Listing 6.24. Initialising a channel using `open`




```
var chan: Channel[string]
open(chan)
```



Values can be sent using the `send` procedure and received using the `recv` procedure. *Listing 6.25* shows how to use both procedures.




Listing 6.25. Sending and receiving data through a channel




```
import os, threadpool   ❶
var chan: Channel[string]
open(chan)

proc sayHello() =
  sleep(1000)           ❷
  chan.send("Hello!")

spawn sayHello()        ❸
doAssert chan.recv() == "Hello!"   ❹
```




|  |  |
| --- | --- |
| [❶](#CO18-1) | The `os` module defines the `sleep` procedure. The `threadpool` module is needed for `spawn`. |
| [❷](#CO18-2) | The `sayHello` procedure will sleep its thread for 1 second before sending a message through `chan`. |
| [❸](#CO18-3) | Execute the `sayHello` procedure in another thread. |
| [❹](#CO18-4) | Block the main thread until a `"Hello!"` is received. |





The `recv` procedure will block until a message is received. You may use the `tryRecv` procedure to get non-blocking behaviour, it returns a tuple consisting of a boolean, which determines whether data was received, and the actual data.


To give you a better idea of how channels work, let me show you how to implement *Listing 6.23* with channels instead of locks. *Listing 6.26* below shows `parallel_incrementer.nim` implemented using channels.




Listing 6.26. `parallel_incrementer.nim` implemented using channels




```
import threadpool

var resultChan: Channel[int]      ❶
open(resultChan)    ❷

proc increment(x: int) =
  var counter = 0   ❸
  for i in 0 .. <x:
    counter.inc
  resultChan.send(counter)        ❹

spawn increment(10_000)
spawn increment(10_000)
sync()              ❺
var total = 0
for i in 0 .. <resultChan.peek:   ❻
  total.inc resultChan.recv()     ❼
echo(total)
```




|  |  |
| --- | --- |
| [❶](#CO19-1) | Define a new global `Channel[int]` variable. |
| [❷](#CO19-2) | Initialise the channel so that messages can be sent through it. |
| [❸](#CO19-3) | This time the `counter` variable is local to the `increment` procedure. |
| [❹](#CO19-4) | Once the counter calculation finishes, its value is sent through the channel. |
| [❺](#CO19-5) | Wait for both of the threads to finish. |
| [❻](#CO19-6) | The `peek` procedure returns the amount of messages waiting to be read inside the channel. |
| [❼](#CO19-7) | Read one of the messages and increment `total` by the message’s value. |





The global `counter` variable is replaced by a global `resultChan` channel. The `increment` procedure increments a local `counter` variable `x` amount of times, and then it sends `counter`'s value through the channel. This is done in two different threads.


The main thread waits for the two threads to finish, at which point it reads the messages which have been sent to the `resultChan`. *Figure 6.7* shows the execution of *Listing 6.26*.




Figure 6.7. Execution of *Listing 6.26*


![ch06 channels](../Images/ch06_channels.png)





6.6  Summary
============



This chapter covered concurrency in Nim. It explained the important difference between concurrency and parallelism, showed the two primary ways to create threads in Nim, and described Nim’s unique threading model. We also discussed parsing, the many different methods to do it in Nim, and ways to parallelise parsing.


This chapter covered:



* The difference between concurrency and parallelism
* Using the `threads` module to create heavyweight threads.
* Using `spawn` and the `threadpool` module to create lightweight threads.
* GC safety in threads and how the compiler enforces it
* Parsing using regular expressions, `parseutils` and more.
* Parallelisation of a parser
* Preventing race conditions using locks and channels.



The next chapter will provide practical information that shows you how to build a simple Twitter clone. You will learn about web development in the next chapter and learn many different aspects of Nim that you have not seen yet.




